# -*- coding: utf-8 -*-
"""red_neuronal1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GRuDpV21_qDKmUtRz7tPBnCSNP1mLUWe
"""

import numpy as np

class Capa:
  """
  Representa una capa oculta o de salida
  """
  
  
  def __init__(self, n_entrada, n_neuronas, activacion = None
               , pesos = None, bias = None):
    
    self.pesos = pesos if pesos is not None else np.random.rand(n_entrada, n_neuronas)
    self.activacion = activacion
    self.bias = bias if bias is not None else np.random.rand(n_neuronas)
    self.ultima_activacion = None
    self.error = None
    self.delta = None
  
  def activar(self, x):
    
    r = np.dot(x, self.pesos) + self.bias
    
    self.ultima_activacion = self.aplicar_activacion(r)
    
    return self.ultima_activacion
  
  
  def aplicar_activacion(self, r):
    
    if self.activacion is None:
      return r
    
    if self.activacion == 'tanh':
      return np.tanh(r)
    
    if self.activacion == 'sigmoide':
      return 1/(1 + np.exp(-r))
    
    return r
  
  def derivada_activacion(self, r):
    
    
    if self.activacion == 'sigmoide':
      return r * (1 - r)
    
    if self.activacion == 'tanh':
      return 1 - r**2
    
    return r



class RedNeuronal:
  
  def __init__(self):
    self.capas = []
    
  def aniadir_capa(self, capa):
    self.capas.append(capa)
    
  def propagacion_hacia_delante(self, X):
    
    for capa in self.capas:
      X = capa.activar(X)
  
    return X
  
  def backpropagation(self, X, y, alfa):
    
    
    salida = self.propagacion_hacia_delante(X)
    
    for i in reversed(range(len(self.capas))):
      
      capa = self.capas[i]
      
      if capa == self.capas[-1]:
        capa.error = y - salida
        
        capa.delta = capa.error * capa.derivada_activacion(salida)
      
      else:
        
        capa_siguiente = self.capas[i + 1]
        capa.error = np.dot(capa_siguiente.pesos, capa_siguiente.delta)
        capa.delta = capa.error * capa.derivada_activacion(capa.ultima_activacion)
    
    for i in range(len(self.capas)):
      
      capa = self.capas[i]
      
      entrada = np.atleast_2d(X if i == 0 else self.capas[i -1].ultima_activacion)
      
      capa.pesos += alfa * capa.delta * entrada.T
  
  
  def entrenar(self, X, y, alfa, epocas):
    
    mses = []
    
    for i in range(epocas):
      
      for j in range(len(X)):
        self.backpropagation(X[j], y[j], alfa)
    
      
      if i % 100 == 0:
        mse = np.mean(np.square(y - self.propagacion_hacia_delante(X)))
        
        mses.append(mse)
        
        print("Epoca", i, "MSE: ", mse)
    
    return mses


